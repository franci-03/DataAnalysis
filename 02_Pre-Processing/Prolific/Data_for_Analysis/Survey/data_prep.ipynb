{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing of Data -  Group with Randomization\n",
    "\n",
    "Data for the Validation of Constructs\n",
    "\n",
    "Some cleaning steps were directly done in Excel:\n",
    "- Replaced the German column names with the English ones\n",
    "- Removed columns that were different from the Lab Data\n",
    "\n",
    "-> Look at readme-data file for more info\n",
    "\n",
    "v2_18.04.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel('2024_04_14_results-survey.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitdate</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>Zufallsgeneratorstartwert</th>\n",
       "      <th>startdate</th>\n",
       "      <th>datestamp</th>\n",
       "      <th>VPNCode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Edu</th>\n",
       "      <th>...</th>\n",
       "      <th>MANI1Time</th>\n",
       "      <th>groupTime535</th>\n",
       "      <th>E2Time</th>\n",
       "      <th>groupTime536</th>\n",
       "      <th>JC2Time</th>\n",
       "      <th>SE2Time</th>\n",
       "      <th>SDT2Time</th>\n",
       "      <th>TASKDIF2Time</th>\n",
       "      <th>PROD2Time</th>\n",
       "      <th>MANI2Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-12 13:45:17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79774926</td>\n",
       "      <td>2024-04-12 13:04:09</td>\n",
       "      <td>2024-04-12 13:45:17</td>\n",
       "      <td>ZZAHE0508</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-12 13:40:12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1555391928</td>\n",
       "      <td>2024-04-12 13:04:27</td>\n",
       "      <td>2024-04-12 13:40:12</td>\n",
       "      <td>ZZEBA0308</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-12 13:33:43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>583800965</td>\n",
       "      <td>2024-04-12 13:04:38</td>\n",
       "      <td>2024-04-12 13:33:43</td>\n",
       "      <td>ZZNRO406</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-12 13:30:12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>716396962</td>\n",
       "      <td>2024-04-12 13:04:42</td>\n",
       "      <td>2024-04-12 13:30:12</td>\n",
       "      <td>ZZSSA0301</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Abitur oder Fachabitur</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1985388160</td>\n",
       "      <td>2024-04-12 13:05:02</td>\n",
       "      <td>2024-04-12 13:09:52</td>\n",
       "      <td>ZZIPU0306</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           submitdate  lastpage  Zufallsgeneratorstartwert  \\\n",
       "0   1  2024-04-12 13:45:17       6.0                   79774926   \n",
       "1   2  2024-04-12 13:40:12       6.0                 1555391928   \n",
       "2   3  2024-04-12 13:33:43       6.0                  583800965   \n",
       "3   4  2024-04-12 13:30:12       6.0                  716396962   \n",
       "4   5                  NaN       2.0                 1985388160   \n",
       "\n",
       "             startdate            datestamp    VPNCode    Gender   AGE  \\\n",
       "0  2024-04-12 13:04:09  2024-04-12 13:45:17  ZZAHE0508  Männlich  26.0   \n",
       "1  2024-04-12 13:04:27  2024-04-12 13:40:12  ZZEBA0308  Weiblich  25.0   \n",
       "2  2024-04-12 13:04:38  2024-04-12 13:33:43   ZZNRO406  Weiblich  30.0   \n",
       "3  2024-04-12 13:04:42  2024-04-12 13:30:12  ZZSSA0301  Weiblich  22.0   \n",
       "4  2024-04-12 13:05:02  2024-04-12 13:09:52  ZZIPU0306  Weiblich  32.0   \n",
       "\n",
       "                      Edu  ...  MANI1Time groupTime535 E2Time groupTime536  \\\n",
       "0                Bachelor  ...        NaN        52.08    NaN       201.09   \n",
       "1                Bachelor  ...        NaN         3.22    NaN       238.06   \n",
       "2                Bachelor  ...        NaN       417.03    NaN       202.43   \n",
       "3  Abitur oder Fachabitur  ...        NaN       167.23    NaN       386.90   \n",
       "4                Bachelor  ...        NaN          NaN    NaN          NaN   \n",
       "\n",
       "  JC2Time SE2Time SDT2Time TASKDIF2Time PROD2Time MANI2Time  \n",
       "0     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "1     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "2     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "3     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "4     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPNCode</th>\n",
       "      <th>id</th>\n",
       "      <th>submitdate</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>Zufallsgeneratorstartwert</th>\n",
       "      <th>startdate</th>\n",
       "      <th>datestamp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Edu</th>\n",
       "      <th>...</th>\n",
       "      <th>MANI1Time</th>\n",
       "      <th>groupTime535</th>\n",
       "      <th>E2Time</th>\n",
       "      <th>groupTime536</th>\n",
       "      <th>JC2Time</th>\n",
       "      <th>SE2Time</th>\n",
       "      <th>SDT2Time</th>\n",
       "      <th>TASKDIF2Time</th>\n",
       "      <th>PROD2Time</th>\n",
       "      <th>MANI2Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZZAHE0508</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-12 13:45:17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79774926</td>\n",
       "      <td>2024-04-12 13:04:09</td>\n",
       "      <td>2024-04-12 13:45:17</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZZEBA0308</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-12 13:40:12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1555391928</td>\n",
       "      <td>2024-04-12 13:04:27</td>\n",
       "      <td>2024-04-12 13:40:12</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZZNRO406</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-12 13:33:43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>583800965</td>\n",
       "      <td>2024-04-12 13:04:38</td>\n",
       "      <td>2024-04-12 13:33:43</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZZSSA0301</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-12 13:30:12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>716396962</td>\n",
       "      <td>2024-04-12 13:04:42</td>\n",
       "      <td>2024-04-12 13:30:12</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Abitur oder Fachabitur</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZZIPU0306</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1985388160</td>\n",
       "      <td>2024-04-12 13:05:02</td>\n",
       "      <td>2024-04-12 13:09:52</td>\n",
       "      <td>Weiblich</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VPNCode  id           submitdate  lastpage  Zufallsgeneratorstartwert  \\\n",
       "0  ZZAHE0508   1  2024-04-12 13:45:17       6.0                   79774926   \n",
       "1  ZZEBA0308   2  2024-04-12 13:40:12       6.0                 1555391928   \n",
       "2   ZZNRO406   3  2024-04-12 13:33:43       6.0                  583800965   \n",
       "3  ZZSSA0301   4  2024-04-12 13:30:12       6.0                  716396962   \n",
       "4  ZZIPU0306   5                  NaN       2.0                 1985388160   \n",
       "\n",
       "             startdate            datestamp    Gender   AGE  \\\n",
       "0  2024-04-12 13:04:09  2024-04-12 13:45:17  Männlich  26.0   \n",
       "1  2024-04-12 13:04:27  2024-04-12 13:40:12  Weiblich  25.0   \n",
       "2  2024-04-12 13:04:38  2024-04-12 13:33:43  Weiblich  30.0   \n",
       "3  2024-04-12 13:04:42  2024-04-12 13:30:12  Weiblich  22.0   \n",
       "4  2024-04-12 13:05:02  2024-04-12 13:09:52  Weiblich  32.0   \n",
       "\n",
       "                      Edu  ...  MANI1Time groupTime535 E2Time groupTime536  \\\n",
       "0                Bachelor  ...        NaN        52.08    NaN       201.09   \n",
       "1                Bachelor  ...        NaN         3.22    NaN       238.06   \n",
       "2                Bachelor  ...        NaN       417.03    NaN       202.43   \n",
       "3  Abitur oder Fachabitur  ...        NaN       167.23    NaN       386.90   \n",
       "4                Bachelor  ...        NaN          NaN    NaN          NaN   \n",
       "\n",
       "  JC2Time SE2Time SDT2Time TASKDIF2Time PROD2Time MANI2Time  \n",
       "0     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "1     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "2     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "3     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "4     NaN     NaN      NaN          NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making \"VPNCode\" the first column\n",
    "cols = ['VPNCode'] + [col for col in df if col != 'VPNCode']\n",
    "df = df[cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'id' values with problems that need to be dropped\n",
    "ids_to_drop = [\n",
    "    5, 14, 17, 19, 24, 25, 26, 36, 37, 42, 49, 50, 52, 54, 56, 57,\n",
    "    62, 65, 66, 76, 77, 81, 82, 1, 6, 7, 46, 51, 53, 74\n",
    "]\n",
    "\n",
    "# Drop rows where the 'id' column is in the ids_to_drop list\n",
    "df = df[~df['id'].isin(ids_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\100661118.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=columns_to_drop, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop unuseful columns\n",
    "columns_to_drop = ['id', 'submitdate', 'lastpage', 'LinktoTool', 'E2', \n",
    "                   'VPNCodeTime', 'GenderTime', 'AGETime', 'EduTime', 'WORKTime', 'AILiteracyTime', \n",
    "                   'PGATTime', 'NGATTime', 'CMVTime', 'NEOTime', 'ERKTime', 'LinktoToolTime', \n",
    "                   'TESTTime', 'JC1Time', 'SE1Time', 'SDT1Time', 'PROD1Time', 'TASKDIF1Time', \n",
    "                   'MANI1Time', 'E2Time', 'JC2Time', 'SE2Time', 'SDT2Time', 'PROD2Time', \n",
    "                   'TASKDIF2Time', 'MANI2Time']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPNCode: ZZRHA2012, Missing in columns: ['MANI2']\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with missing values\n",
    "missing_info = df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Report VPNCode and column names with missing values\n",
    "for index, row in missing_info.iterrows():\n",
    "    missing_columns = row[row.isnull()].index.tolist()\n",
    "    vpn_code = row['VPNCode']\n",
    "    print(f\"VPNCode: {vpn_code}, Missing in columns: {missing_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known before and it is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Likert scale responses to numerical codes -> Changes in the mapping were done\n",
    "likert_mapping = {\n",
    "    \"Trifft gar nicht zu\": 1,\n",
    "    \"Trifft eher nicht zu\": 2,\n",
    "    \"Teils, teils\": 3,\n",
    "    \"Trifft teilweise zu\": 4,\n",
    "    \"Trifft voll und ganz zu\": 5,\n",
    "    \"Gar nicht zufriedenstellend\": 1,\n",
    "    \"Eher nicht zufriedenstellend\": 2,\n",
    "    \"Eher zufriedenstellend\": 4,\n",
    "    \"Voll zufriedenstellend\": 5,\n",
    "    \"Extrem schwierig\": 1,\n",
    "    \"Eher schwierig\": 2,\n",
    "    \"Eher leicht\": 4,\n",
    "    \"Extrem leicht\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3678281005.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].map(likert_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Apply mapping to all columns where conversion is needed.\n",
    "for column in df.select_dtypes(include='object').columns:  #Only object-type columns need conversion\n",
    "    if df[column].isin(likert_mapping.keys()).any():\n",
    "        df[column] = df[column].map(likert_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPNCode: ZZRHA2012, Missing in columns: ['MANI2']\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for total time in minutes\n",
    "df['datestamp'] = pd.to_datetime(df['datestamp'])\n",
    "df['startdate'] = pd.to_datetime(df['startdate'])\n",
    "df['total_time'] = (df['datestamp'] - df['startdate']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns afterwards\n",
    "df.drop(columns=['datestamp', 'startdate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing time-related columns by 60\n",
    "time_columns = ['interviewtime', 'groupTime531', 'groupTime532', 'groupTime534', 'groupTime533', 'groupTime535', 'groupTime536']\n",
    "df[time_columns] = df[time_columns].div(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in 'Gender' with underscores\n",
    "df['Gender'] = df['Gender'].str.replace(' ', '_')\n",
    "\n",
    "# One-hot encode 'Gender' column -> Dummy for each Gender\n",
    "gender_dummies = pd.get_dummies(df['Gender'], prefix='Gender')\n",
    "df = pd.concat([df, gender_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Gender' column as it is no longer needed\n",
    "df.drop('Gender', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in 'Edu' with underscores for convenience\n",
    "df['Edu'] = df['Edu'].str.replace(' ', '_')\n",
    "\n",
    "# One-hot encode 'Edu' column -> Dummy for each Education\n",
    "edu_dummies = pd.get_dummies(df['Edu'], prefix='Edu')\n",
    "df = pd.concat([df, edu_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Edu' column as it is no longer needed\n",
    "df.drop('Edu', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert WORK column values to numeric and remove percentage signs\n",
    "df['WORK'] = df['WORK'].replace('%', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants passed all tests\n"
     ]
    }
   ],
   "source": [
    "# After Discussion with Eva: Not really a Test. But it has no influence so I can just keep it like this\n",
    "\n",
    "# Check if ERK and TEST columns have \"Ja\" for all rows \n",
    "# If all pass the two columns are dropped otherwise the VPNCodes are stated\n",
    "if (df['ERK'] == \"Ja\").all() and (df['TEST'] == \"Ja\").all():\n",
    "    print(\"Participants passed all tests\")\n",
    "    df.drop(columns=['ERK', 'TEST'], inplace=True)\n",
    "else:\n",
    "    failed_tests = df[(df['ERK'] != \"Ja\") | (df['TEST'] != \"Ja\")]['VPNCode']\n",
    "    print(f\"Not all participants passed the tests. Affected VPNCode rows: {failed_tests.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in the 'WORK' column are floats.\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in the 'WORK' column are integers or floats\n",
    "are_all_numbers = df['WORK'].apply(lambda x: isinstance(x, (float))).all()\n",
    "\n",
    "# Print the result\n",
    "if are_all_numbers:\n",
    "    print(\"All values in the 'WORK' column are floats.\")\n",
    "else:\n",
    "    print(\"Not all values in the 'WORK' column are integers or floats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORK column contains values <= 0. Affected VPNCode rows: ['ZZSSA0301', 'ZZUWA3006', 'ZZELU0612', 'ZZAH0702', 'ZZOHA2303', 'ZZEOT3110', 'ZZAKI601']\n"
     ]
    }
   ],
   "source": [
    "# Check if all numbers in the WORK column are > 0\n",
    "if (df['WORK'] <= 0).any():\n",
    "    affected_vpn = df[df['WORK'] <= 0]['VPNCode']\n",
    "    print(f\"WORK column contains values <= 0. Affected VPNCode rows: {affected_vpn.tolist()}\")\n",
    "else:\n",
    "    print(\"All WORK column numbers are > 0.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some people aren't working right now but maybe were in the past -> If Prolific let them pass the requirements were fulfilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants passed all AC tests\n"
     ]
    }
   ],
   "source": [
    "# Check if JC2[AC] column has 4 as an answer for all rows\n",
    "# If this is the case the column is dropped otherwise the VPNCodes are stated\n",
    "if (df['JC2[AC]'] == 4).all():\n",
    "    print(\"Participants passed all AC tests\")\n",
    "    df.drop(columns=['JC2[AC]'], inplace=True)\n",
    "else:\n",
    "    failed_ac_test = df[df['JC2[AC]'] != 4]['VPNCode']\n",
    "    print(f\"Not all participants passed the AC test. Affected VPNCode rows: {failed_ac_test.tolist()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column 'JC2[AC]' as it is no longer needed\n",
    "df.drop(columns=['JC2[AC]'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPNCode</th>\n",
       "      <th>Zufallsgeneratorstartwert</th>\n",
       "      <th>AGE</th>\n",
       "      <th>WORK</th>\n",
       "      <th>AILiteracy[Use1]</th>\n",
       "      <th>AILiteracy[Use2]</th>\n",
       "      <th>AILiteracy[Use3]</th>\n",
       "      <th>AILiteracy[Use4]</th>\n",
       "      <th>AILiteracy[Use5]</th>\n",
       "      <th>AILiteracy[Use6]</th>\n",
       "      <th>...</th>\n",
       "      <th>groupTime536</th>\n",
       "      <th>total_time</th>\n",
       "      <th>Gender_Männlich</th>\n",
       "      <th>Gender_Weiblich</th>\n",
       "      <th>Edu_Abgeschlossene_Berufsausbildung</th>\n",
       "      <th>Edu_Abitur_oder_Fachabitur</th>\n",
       "      <th>Edu_Bachelor</th>\n",
       "      <th>Edu_Doktortitel</th>\n",
       "      <th>Edu_Master</th>\n",
       "      <th>Edu_Mittlere_Reife_(Realschulabschluss)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZZEBA0308</td>\n",
       "      <td>1555391928</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.967667</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZZNRO406</td>\n",
       "      <td>583800965</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.373833</td>\n",
       "      <td>29.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZZSSA0301</td>\n",
       "      <td>716396962</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.448333</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZZAWA0212</td>\n",
       "      <td>875831755</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.050667</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZZKO1608</td>\n",
       "      <td>405906470</td>\n",
       "      <td>37.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.143000</td>\n",
       "      <td>19.733333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VPNCode  Zufallsgeneratorstartwert   AGE   WORK  AILiteracy[Use1]  \\\n",
       "1  ZZEBA0308                 1555391928  25.0  100.0                 5   \n",
       "2   ZZNRO406                  583800965  30.0  100.0                 2   \n",
       "3  ZZSSA0301                  716396962  22.0    0.0                 5   \n",
       "7  ZZAWA0212                  875831755  22.0  100.0                 5   \n",
       "8   ZZKO1608                  405906470  37.0  100.0                 5   \n",
       "\n",
       "   AILiteracy[Use2]  AILiteracy[Use3]  AILiteracy[Use4]  AILiteracy[Use5]  \\\n",
       "1                 5                 5                 5                 5   \n",
       "2                 4                 4                 4                 4   \n",
       "3                 5                 5                 5                 5   \n",
       "7                 5                 5                 5                 5   \n",
       "8                 4                 4                 4                 4   \n",
       "\n",
       "   AILiteracy[Use6]  ...  groupTime536  total_time  Gender_Männlich  \\\n",
       "1                 5  ...      3.967667   35.750000            False   \n",
       "2                 2  ...      3.373833   29.083333            False   \n",
       "3                 5  ...      6.448333   25.500000            False   \n",
       "7                 5  ...      6.050667   20.750000             True   \n",
       "8                 4  ...      6.143000   19.733333             True   \n",
       "\n",
       "   Gender_Weiblich  Edu_Abgeschlossene_Berufsausbildung  \\\n",
       "1             True                                False   \n",
       "2             True                                False   \n",
       "3             True                                False   \n",
       "7            False                                False   \n",
       "8            False                                False   \n",
       "\n",
       "   Edu_Abitur_oder_Fachabitur  Edu_Bachelor  Edu_Doktortitel  Edu_Master  \\\n",
       "1                       False          True            False       False   \n",
       "2                       False          True            False       False   \n",
       "3                        True         False            False       False   \n",
       "7                        True         False            False       False   \n",
       "8                       False          True            False       False   \n",
       "\n",
       "   Edu_Mittlere_Reife_(Realschulabschluss)  \n",
       "1                                    False  \n",
       "2                                    False  \n",
       "3                                    False  \n",
       "7                                    False  \n",
       "8                                    False  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unuseful columns \n",
    "df.drop(columns=['Zufallsgeneratorstartwert'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF in a new CSV-File \n",
    "df.to_csv('data_prep_cleaned.csv', index=False, encoding='utf-8-sig', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# df = pd.read_csv('data_prep_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Literacy Constructs\n",
    "df['AILiteracy[Use]'] = df[['AILiteracy[Use1]', 'AILiteracy[Use2]', 'AILiteracy[Use3]', 'AILiteracy[Use4]', 'AILiteracy[Use5]', 'AILiteracy[Use6]']].mean(axis=1)\n",
    "df['AILiteracy[Kno]'] = df[['AILiteracy[Kno1]', 'AILiteracy[Kno2]', 'AILiteracy[Kno3]', 'AILiteracy[Kno4]', 'AILiteracy[Kno5]', 'AILiteracy[Kno6]']].mean(axis=1)\n",
    "df['AILiteracy[Det]'] = df[['AILiteracy[Det1]', 'AILiteracy[Det2]', 'AILiteracy[Det3]']].mean(axis=1)\n",
    "df['AILiteracy[Eth]'] = df[['AILiteracy[Eth1]', 'AILiteracy[Eth3]']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Attitudes towards AI Constructs\n",
    "df['PGAT'] = df[['PGAT[PGAT1]', 'PGAT[PGAT2]', 'PGAT[PGAT3]']].mean(axis=1)\n",
    "df['NGAT'] = df[['NGAT[NGAT1]', 'NGAT[NGAT2]', 'NGAT[NGAT3]']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Method Bias Construct\n",
    "df['CMV'] = df[['CMV[SQ001]', 'CMV[SQ002]', 'CMV[SQ003]']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\2153840115.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['NEO[O]'] = df[['NEO[O1]', 'NEO[O2]', 'NEO[O3]', 'NEO[O4]', 'NEO[O5R]']].mean(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Big Five Personality Traits (NEO) Constructs\n",
    "df['NEO[E]'] = df[['NEO[E1R]', 'NEO[E2]', 'NEO[E3R]', 'NEO[E4]']].mean(axis=1)\n",
    "df['NEO[A]'] = df[['NEO[V1R]', 'NEO[V2]', 'NEO[V3R]', 'NEO[V4R]']].mean(axis=1)\n",
    "df['NEO[C]'] = df[['NEO[G1]', 'NEO[G2R]', 'NEO[G3]', 'NEO[G4]']].mean(axis=1)\n",
    "df['NEO[N]'] = df[['NEO[N1]', 'NEO[N2R]', 'NEO[N3]', 'NEO[N4]']].mean(axis=1)\n",
    "df['NEO[O]'] = df[['NEO[O1]', 'NEO[O2]', 'NEO[O3]', 'NEO[O4]', 'NEO[O5R]']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3829454071.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['JC1[IStR]'] = df[['JC1[IStR1]', 'JC1[IStR2]', 'JC1[IStR3]', 'JC1[IStR4]', 'JC1[IStR5]']].mean(axis=1)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3829454071.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['JC1[HRJD]'] = df[['JC1[HRJD1]', 'JC1[HRJD2]', 'JC1[HRJD3]', 'JC1[ICJD1]']].mean(axis=1) # *added JC1[ICJD1] because it was wrongly classified (it is part of HRJD)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3829454071.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['JC2[IStR]'] = df[['JC2[2IStR1]', 'JC2[2IStR2]', 'JC2[2IStR3]', 'JC2[2IStR4]', 'JC2[2IStR5]']].mean(axis=1)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_5176\\3829454071.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['JC2[HRJD]'] = df[['JC2[2HRJD1]', 'JC2[2HRJD2]', 'JC2[2HRJD5]', 'JC2[2HRJD6]']].mean(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Job Crafting Constructs -> *Changes made because of errors in the column naming / item categorization\n",
    "df['JC1[IStR]'] = df[['JC1[IStR1]', 'JC1[IStR2]', 'JC1[IStR3]', 'JC1[IStR4]', 'JC1[IStR5]']].mean(axis=1)\n",
    "df['JC1[HRJD]'] = df[['JC1[HRJD1]', 'JC1[HRJD2]', 'JC1[HRJD3]', 'JC1[ICJD1]']].mean(axis=1) # *added JC1[ICJD1] because it was wrongly classified (it is part of HRJD)\n",
    "df['JC2[IStR]'] = df[['JC2[2IStR1]', 'JC2[2IStR2]', 'JC2[2IStR3]', 'JC2[2IStR4]', 'JC2[2IStR5]']].mean(axis=1)\n",
    "df['JC2[HRJD]'] = df[['JC2[2HRJD1]', 'JC2[2HRJD2]', 'JC2[2HRJD5]', 'JC2[2HRJD6]']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original columns to clean up the DataFrame and reduce complexity\n",
    "columns_to_drop = [\n",
    "    'AILiteracy[Use1]', 'AILiteracy[Use2]', 'AILiteracy[Use3]', 'AILiteracy[Use4]', 'AILiteracy[Use5]', 'AILiteracy[Use6]',\n",
    "    'AILiteracy[Kno1]', 'AILiteracy[Kno2]', 'AILiteracy[Kno3]', 'AILiteracy[Kno4]', 'AILiteracy[Kno5]', 'AILiteracy[Kno6]',\n",
    "    'AILiteracy[Det1]', 'AILiteracy[Det2]', 'AILiteracy[Det3]', \n",
    "    'AILiteracy[Eth1]', 'AILiteracy[Eth3]',\n",
    "    'PGAT[PGAT1]', 'PGAT[PGAT2]', 'PGAT[PGAT3]',\n",
    "    'NGAT[NGAT1]', 'NGAT[NGAT2]', 'NGAT[NGAT3]',\n",
    "    'CMV[SQ001]', 'CMV[SQ002]', 'CMV[SQ003]',\n",
    "    'NEO[E1R]', 'NEO[E2]', 'NEO[E3R]', 'NEO[E4]',\n",
    "    'NEO[V1R]', 'NEO[V2]', 'NEO[V3R]', 'NEO[V4R]',\n",
    "    'NEO[G1]', 'NEO[G2R]', 'NEO[G3]', 'NEO[G4]',\n",
    "    'NEO[N1]', 'NEO[N2R]', 'NEO[N3]', 'NEO[N4]',\n",
    "    'NEO[O1]', 'NEO[O2]', 'NEO[O3]', 'NEO[O4]', 'NEO[O5R]',\n",
    "    'JC1[IStR1]', 'JC1[IStR2]', 'JC1[IStR3]', 'JC1[IStR4]', 'JC1[IStR5]',\n",
    "    'JC1[HRJD1]', 'JC1[HRJD2]', 'JC1[HRJD3]', 'JC1[ICJD1]', # *added JC1[ICJD1] \n",
    "    'JC2[2IStR1]', 'JC2[2IStR2]', 'JC2[2IStR3]', 'JC2[2IStR4]', 'JC2[2IStR5]',\n",
    "    'JC2[2HRJD1]', 'JC2[2HRJD2]', 'JC2[2HRJD5]', 'JC2[2HRJD6]'\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df.rename(columns={\n",
    "    'SDT1[SDT1]': 'SDT1[AUT]',\n",
    "    'SDT1[SDT2]': 'SDT1[COM]',\n",
    "    'SDT2[2SDT1]': 'SDT2[AUT]',\n",
    "    'SDT2[2SDT2]': 'SDT2[COM]',\n",
    "    'PROD1[SQ001]': 'PROD1',\n",
    "    'TASKDIF1[SQ001]': 'TASKDIF1',\n",
    "    'PROD2[SQ001]': 'PROD2',\n",
    "    'TASKDIF2[SQ001]': 'TASKDIF2'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VPNCode', 'AGE', 'WORK', 'SE1', 'SDT1[AUT]', 'SDT1[COM]', 'TASKDIF1', 'PROD1', 'MANI1', 'SE2', 'SDT2[AUT]', 'SDT2[COM]', 'TASKDIF2', 'PROD2', 'MANI2', 'interviewtime', 'groupTime531', 'groupTime532', 'groupTime534', 'groupTime533', 'groupTime535', 'groupTime536', 'total_time', 'Gender_Männlich', 'Gender_Weiblich', 'Edu_Abgeschlossene_Berufsausbildung', 'Edu_Abitur_oder_Fachabitur', 'Edu_Bachelor', 'Edu_Doktortitel', 'Edu_Master', 'Edu_Mittlere_Reife_(Realschulabschluss)', 'AILiteracy[Use]', 'AILiteracy[Kno]', 'AILiteracy[Det]', 'AILiteracy[Eth]', 'PGAT', 'NGAT', 'CMV', 'NEO[E]', 'NEO[A]', 'NEO[C]', 'NEO[N]', 'NEO[O]', 'JC1[IStR]', 'JC1[HRJD]', 'JC2[IStR]', 'JC2[HRJD]']\n"
     ]
    }
   ],
   "source": [
    "# Print the list of column names\n",
    "column_names = df.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the desired order of columns\n",
    "# If any are missing or named differently, adjust the list accordingly\n",
    "new_column_order = [\n",
    "    'VPNCode', 'AGE', 'WORK', \n",
    "    'Gender_Männlich', 'Gender_Weiblich', \n",
    "    'Edu_Abgeschlossene_Berufsausbildung', 'Edu_Mittlere_Reife_(Realschulabschluss)', 'Edu_Abitur_oder_Fachabitur', 'Edu_Bachelor', 'Edu_Master', 'Edu_Doktortitel',\n",
    "    'AILiteracy[Use]', 'AILiteracy[Kno]', 'AILiteracy[Det]', 'AILiteracy[Eth]',\n",
    "    'PGAT', 'NGAT', 'CMV', 'NEO[E]', 'NEO[A]', 'NEO[C]', 'NEO[N]', 'NEO[O]',\n",
    "    'JC1[IStR]', 'JC1[HRJD]', 'SE1', 'SDT1[AUT]', 'SDT1[COM]', 'PROD1', 'TASKDIF1', 'MANI1',\n",
    "    'JC2[IStR]', 'JC2[HRJD]', 'SE2', 'SDT2[AUT]', 'SDT2[COM]', 'PROD2', 'TASKDIF2', 'MANI2',\n",
    "    'total_time', 'interviewtime', 'groupTime531', 'groupTime532', 'groupTime534', 'groupTime533', 'groupTime535', 'groupTime536'\n",
    "]\n",
    "\n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming time columns (taken from the German translation)\n",
    "df.rename(columns={\n",
    "    'interviewtime': 'syst_total_time',\n",
    "    'groupTime531': 'time_demogr',\n",
    "    'groupTime532': 'time_pers',\n",
    "    'groupTime534': 'time_task1',\n",
    "    'groupTime533': 'time_survey1',\n",
    "    'groupTime535': 'time_task2',\n",
    "    'groupTime536': 'time_survey2'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPNCode</th>\n",
       "      <th>AGE</th>\n",
       "      <th>WORK</th>\n",
       "      <th>Gender_Männlich</th>\n",
       "      <th>Gender_Weiblich</th>\n",
       "      <th>Edu_Abgeschlossene_Berufsausbildung</th>\n",
       "      <th>Edu_Mittlere_Reife_(Realschulabschluss)</th>\n",
       "      <th>Edu_Abitur_oder_Fachabitur</th>\n",
       "      <th>Edu_Bachelor</th>\n",
       "      <th>Edu_Master</th>\n",
       "      <th>...</th>\n",
       "      <th>TASKDIF2</th>\n",
       "      <th>MANI2</th>\n",
       "      <th>total_time</th>\n",
       "      <th>syst_total_time</th>\n",
       "      <th>time_demogr</th>\n",
       "      <th>time_pers</th>\n",
       "      <th>time_task1</th>\n",
       "      <th>time_survey1</th>\n",
       "      <th>time_task2</th>\n",
       "      <th>time_survey2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZZEBA0308</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ich sollte eine Kommunikationsstrategie entwic...</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>21.029833</td>\n",
       "      <td>4.679333</td>\n",
       "      <td>1.335333</td>\n",
       "      <td>6.123167</td>\n",
       "      <td>4.870667</td>\n",
       "      <td>0.053667</td>\n",
       "      <td>3.967667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZZNRO406</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Mir stand ein generatives Textprogramm zur Ver...</td>\n",
       "      <td>29.083333</td>\n",
       "      <td>29.111167</td>\n",
       "      <td>4.026833</td>\n",
       "      <td>1.107667</td>\n",
       "      <td>9.116833</td>\n",
       "      <td>4.535500</td>\n",
       "      <td>6.950500</td>\n",
       "      <td>3.373833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZZSSA0301</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Ich musste zunächst schnell die gegebene Situa...</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.566000</td>\n",
       "      <td>5.850667</td>\n",
       "      <td>1.538000</td>\n",
       "      <td>3.944333</td>\n",
       "      <td>4.997500</td>\n",
       "      <td>2.787167</td>\n",
       "      <td>6.448333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZZAWA0212</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Einen One Pager zu einer einwöchigen Klimastra...</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>20.772667</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>1.501500</td>\n",
       "      <td>5.711333</td>\n",
       "      <td>3.551500</td>\n",
       "      <td>0.067667</td>\n",
       "      <td>6.050667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZZKO1608</td>\n",
       "      <td>37.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>ich muss nur paar Sätzen an der KI Hilfsmittel...</td>\n",
       "      <td>19.733333</td>\n",
       "      <td>19.773667</td>\n",
       "      <td>4.368833</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>5.228333</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>0.074333</td>\n",
       "      <td>6.143000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VPNCode   AGE   WORK  Gender_Männlich  Gender_Weiblich  \\\n",
       "1  ZZEBA0308  25.0  100.0            False             True   \n",
       "2   ZZNRO406  30.0  100.0            False             True   \n",
       "3  ZZSSA0301  22.0    0.0            False             True   \n",
       "7  ZZAWA0212  22.0  100.0             True            False   \n",
       "8   ZZKO1608  37.0  100.0             True            False   \n",
       "\n",
       "   Edu_Abgeschlossene_Berufsausbildung  \\\n",
       "1                                False   \n",
       "2                                False   \n",
       "3                                False   \n",
       "7                                False   \n",
       "8                                False   \n",
       "\n",
       "   Edu_Mittlere_Reife_(Realschulabschluss)  Edu_Abitur_oder_Fachabitur  \\\n",
       "1                                    False                       False   \n",
       "2                                    False                       False   \n",
       "3                                    False                        True   \n",
       "7                                    False                        True   \n",
       "8                                    False                       False   \n",
       "\n",
       "   Edu_Bachelor  Edu_Master  ...  TASKDIF2  \\\n",
       "1          True       False  ...         1   \n",
       "2          True       False  ...         3   \n",
       "3         False       False  ...         3   \n",
       "7         False       False  ...         4   \n",
       "8          True       False  ...         2   \n",
       "\n",
       "                                               MANI2  total_time  \\\n",
       "1  Ich sollte eine Kommunikationsstrategie entwic...   35.750000   \n",
       "2  Mir stand ein generatives Textprogramm zur Ver...   29.083333   \n",
       "3  Ich musste zunächst schnell die gegebene Situa...   25.500000   \n",
       "7  Einen One Pager zu einer einwöchigen Klimastra...   20.750000   \n",
       "8  ich muss nur paar Sätzen an der KI Hilfsmittel...   19.733333   \n",
       "\n",
       "   syst_total_time  time_demogr  time_pers  time_task1  time_survey1  \\\n",
       "1        21.029833     4.679333   1.335333    6.123167      4.870667   \n",
       "2        29.111167     4.026833   1.107667    9.116833      4.535500   \n",
       "3        25.566000     5.850667   1.538000    3.944333      4.997500   \n",
       "7        20.772667     3.890000   1.501500    5.711333      3.551500   \n",
       "8        19.773667     4.368833   0.871667    5.228333      3.087500   \n",
       "\n",
       "   time_task2  time_survey2  \n",
       "1    0.053667      3.967667  \n",
       "2    6.950500      3.373833  \n",
       "3    2.787167      6.448333  \n",
       "7    0.067667      6.050667  \n",
       "8    0.074333      6.143000  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF in a new CSV-File \n",
    "df.to_csv('data_prep_constructs.csv', index=False, encoding='utf-8-sig', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
