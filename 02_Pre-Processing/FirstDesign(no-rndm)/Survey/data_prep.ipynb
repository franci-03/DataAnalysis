{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing of Data - Group without Randomization\n",
    "\n",
    "The column names were changed in Excel (English teranslation). \n",
    "Not everything is the same as for the group with randomization:\n",
    "- MANI1 is not measured\n",
    "- The column JC1[ICJD2] is additonally measured\n",
    "\n",
    "v1_23.03.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel('20240308_results-JCsurvey_diff-headers-excel.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitdate</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>startlanguage</th>\n",
       "      <th>seed</th>\n",
       "      <th>startdate</th>\n",
       "      <th>datestamp</th>\n",
       "      <th>VPNCode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>TASKDIF1Time</th>\n",
       "      <th>groupTime535</th>\n",
       "      <th>E2Time</th>\n",
       "      <th>groupTime536</th>\n",
       "      <th>JC2Time</th>\n",
       "      <th>SE2Time</th>\n",
       "      <th>SDT2Time</th>\n",
       "      <th>PROD2Time</th>\n",
       "      <th>TASKDIF2Time</th>\n",
       "      <th>MANI2Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-28 10:43:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>489428441</td>\n",
       "      <td>2024-02-28 10:08:00</td>\n",
       "      <td>2024-02-28 10:43:00</td>\n",
       "      <td>ABO2606</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-28 13:05:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>193910323</td>\n",
       "      <td>2024-02-28 12:42:00</td>\n",
       "      <td>2024-02-28 13:05:00</td>\n",
       "      <td>APE2704</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>683.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-02-28 14:12:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>29352144</td>\n",
       "      <td>2024-02-28 13:38:00</td>\n",
       "      <td>2024-02-28 14:12:00</td>\n",
       "      <td>SSG0102</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>894.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-28 15:32:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>1443700134</td>\n",
       "      <td>2024-02-28 14:46:00</td>\n",
       "      <td>2024-02-28 15:32:00</td>\n",
       "      <td>ECH2807</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1174.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-02-29 09:15:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>2009257017</td>\n",
       "      <td>2024-02-29 08:47:00</td>\n",
       "      <td>2024-02-29 09:15:00</td>\n",
       "      <td>AST1210</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          submitdate  lastpage startlanguage        seed  \\\n",
       "0   2 2024-02-28 10:43:00         6            de   489428441   \n",
       "1   3 2024-02-28 13:05:00         6            de   193910323   \n",
       "2   4 2024-02-28 14:12:00         6            de    29352144   \n",
       "3   5 2024-02-28 15:32:00         6            de  1443700134   \n",
       "4   6 2024-02-29 09:15:00         6            de  2009257017   \n",
       "\n",
       "            startdate           datestamp  VPNCode    Gender  AGE  ...  \\\n",
       "0 2024-02-28 10:08:00 2024-02-28 10:43:00  ABO2606  Männlich   22  ...   \n",
       "1 2024-02-28 12:42:00 2024-02-28 13:05:00  APE2704  Männlich   20  ...   \n",
       "2 2024-02-28 13:38:00 2024-02-28 14:12:00  SSG0102  Männlich   20  ...   \n",
       "3 2024-02-28 14:46:00 2024-02-28 15:32:00  ECH2807  Männlich   21  ...   \n",
       "4 2024-02-29 08:47:00 2024-02-29 09:15:00  AST1210  Männlich   25  ...   \n",
       "\n",
       "  TASKDIF1Time groupTime535 E2Time groupTime536 JC2Time SE2Time SDT2Time  \\\n",
       "0          NaN         4.01    NaN       690.58     NaN     NaN      NaN   \n",
       "1          NaN        10.81    NaN       683.10     NaN     NaN      NaN   \n",
       "2          NaN       894.66    NaN       157.54     NaN     NaN      NaN   \n",
       "3          NaN      1174.46    NaN       109.27     NaN     NaN      NaN   \n",
       "4          NaN       386.73    NaN       177.58     NaN     NaN      NaN   \n",
       "\n",
       "  PROD2Time TASKDIF2Time MANI2Time  \n",
       "0       NaN          NaN       NaN  \n",
       "1       NaN          NaN       NaN  \n",
       "2       NaN          NaN       NaN  \n",
       "3       NaN          NaN       NaN  \n",
       "4       NaN          NaN       NaN  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPNCode</th>\n",
       "      <th>id</th>\n",
       "      <th>submitdate</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>startlanguage</th>\n",
       "      <th>seed</th>\n",
       "      <th>startdate</th>\n",
       "      <th>datestamp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>TASKDIF1Time</th>\n",
       "      <th>groupTime535</th>\n",
       "      <th>E2Time</th>\n",
       "      <th>groupTime536</th>\n",
       "      <th>JC2Time</th>\n",
       "      <th>SE2Time</th>\n",
       "      <th>SDT2Time</th>\n",
       "      <th>PROD2Time</th>\n",
       "      <th>TASKDIF2Time</th>\n",
       "      <th>MANI2Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABO2606</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-28 10:43:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>489428441</td>\n",
       "      <td>2024-02-28 10:08:00</td>\n",
       "      <td>2024-02-28 10:43:00</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APE2704</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-28 13:05:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>193910323</td>\n",
       "      <td>2024-02-28 12:42:00</td>\n",
       "      <td>2024-02-28 13:05:00</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>683.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SSG0102</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-02-28 14:12:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>29352144</td>\n",
       "      <td>2024-02-28 13:38:00</td>\n",
       "      <td>2024-02-28 14:12:00</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>894.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECH2807</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-28 15:32:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>1443700134</td>\n",
       "      <td>2024-02-28 14:46:00</td>\n",
       "      <td>2024-02-28 15:32:00</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1174.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AST1210</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-02-29 09:15:00</td>\n",
       "      <td>6</td>\n",
       "      <td>de</td>\n",
       "      <td>2009257017</td>\n",
       "      <td>2024-02-29 08:47:00</td>\n",
       "      <td>2024-02-29 09:15:00</td>\n",
       "      <td>Männlich</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VPNCode  id          submitdate  lastpage startlanguage        seed  \\\n",
       "0  ABO2606   2 2024-02-28 10:43:00         6            de   489428441   \n",
       "1  APE2704   3 2024-02-28 13:05:00         6            de   193910323   \n",
       "2  SSG0102   4 2024-02-28 14:12:00         6            de    29352144   \n",
       "3  ECH2807   5 2024-02-28 15:32:00         6            de  1443700134   \n",
       "4  AST1210   6 2024-02-29 09:15:00         6            de  2009257017   \n",
       "\n",
       "            startdate           datestamp    Gender  AGE  ... TASKDIF1Time  \\\n",
       "0 2024-02-28 10:08:00 2024-02-28 10:43:00  Männlich   22  ...          NaN   \n",
       "1 2024-02-28 12:42:00 2024-02-28 13:05:00  Männlich   20  ...          NaN   \n",
       "2 2024-02-28 13:38:00 2024-02-28 14:12:00  Männlich   20  ...          NaN   \n",
       "3 2024-02-28 14:46:00 2024-02-28 15:32:00  Männlich   21  ...          NaN   \n",
       "4 2024-02-29 08:47:00 2024-02-29 09:15:00  Männlich   25  ...          NaN   \n",
       "\n",
       "  groupTime535 E2Time groupTime536 JC2Time SE2Time SDT2Time PROD2Time  \\\n",
       "0         4.01    NaN       690.58     NaN     NaN      NaN       NaN   \n",
       "1        10.81    NaN       683.10     NaN     NaN      NaN       NaN   \n",
       "2       894.66    NaN       157.54     NaN     NaN      NaN       NaN   \n",
       "3      1174.46    NaN       109.27     NaN     NaN      NaN       NaN   \n",
       "4       386.73    NaN       177.58     NaN     NaN      NaN       NaN   \n",
       "\n",
       "  TASKDIF2Time MANI2Time  \n",
       "0          NaN       NaN  \n",
       "1          NaN       NaN  \n",
       "2          NaN       NaN  \n",
       "3          NaN       NaN  \n",
       "4          NaN       NaN  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making \"VPNCode\" the first column\n",
    "cols = ['VPNCode'] + [col for col in df if col != 'VPNCode']\n",
    "df = df[cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unuseful columns (there is a difference between first and second round)\n",
    "columns_to_drop = ['id', 'submitdate', 'lastpage', 'startlanguage', 'seed', 'LinktoTool', 'E2', \n",
    "                   'VPNCodeTime', 'GenderTime', 'AGETime', 'EduTime', 'WORKTime', 'AILiteracyTime', \n",
    "                   'PGATTime', 'NGATTime', 'CMVTime', 'NEOTime', 'ERKTime', 'LinktoToolTime', \n",
    "                   'TESTTime', 'JC1Time', 'SE1Time', 'SDT1Time', 'PROD1Time', 'TASKDIF1Time', \n",
    "                   'E2Time', 'JC2Time', 'SE2Time', 'SDT2Time', 'PROD2Time', \n",
    "                   'TASKDIF2Time', 'MANI2Time']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Likert scale responses to numerical codes\n",
    "likert_mapping = {\n",
    "    \"Trifft gar nicht zu\": 1,\n",
    "    \"Trifft eher nicht zu\": 2,\n",
    "    \"Teils, teils\": 3,\n",
    "    \"Trifft teilweise zu\": 4,\n",
    "    \"Trifft voll zu\": 5,\n",
    "    \"Gar nicht zufriedenstellend\": 1,\n",
    "    \"Eher nicht zufriedenstellend\": 2,\n",
    "    \"Eher zufriedenstellend\": 4,\n",
    "    \"Voll zufriedenstellend\": 5,\n",
    "    \"Extrem schwierig\": 1,\n",
    "    \"Eher schwierig\": 2,\n",
    "    \"Eher leicht\": 4,\n",
    "    \"Extrem leicht\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping to all columns where this conversion is needed.\n",
    "for column in df.select_dtypes(include='object').columns:  # Assuming only object-type columns need conversion\n",
    "    if df[column].isin(likert_mapping.keys()).any():\n",
    "        df[column] = df[column].map(likert_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for total time in minutes\n",
    "df['datestamp'] = pd.to_datetime(df['datestamp'])\n",
    "df['startdate'] = pd.to_datetime(df['startdate'])\n",
    "df['total_time'] = (df['datestamp'] - df['startdate']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns afterwards\n",
    "df.drop(columns=['datestamp', 'startdate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing  time-related columns by 60 to get minutes\n",
    "time_columns = ['interviewtime', 'groupTime531', 'groupTime532', 'groupTime534', 'groupTime533', 'groupTime535', 'groupTime536']\n",
    "df[time_columns] = df[time_columns].div(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in 'Edu' with underscores\n",
    "df['Gender'] = df['Gender'].str.replace(' ', '_')\n",
    "\n",
    "# One-hot encode 'Gender' column -> Dummy for each Gender\n",
    "gender_dummies = pd.get_dummies(df['Gender'], prefix='Gender')\n",
    "df = pd.concat([df, gender_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Gender' column as it is no longer needed\n",
    "df.drop('Gender', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in 'Edu' with underscores\n",
    "df['Edu'] = df['Edu'].str.replace(' ', '_')\n",
    "\n",
    "# One-hot encode 'Edu' column -> Dummy for each Education\n",
    "edu_dummies = pd.get_dummies(df['Edu'], prefix='Edu')\n",
    "df = pd.concat([df, edu_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'Edu' column as it is no longer needed\n",
    "df.drop('Edu', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    VBA1706\n",
      "Name: VPNCode, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Test for non-convertible values in WORK column and print affected VPNCode \n",
    "# Error because of wrong input in WORK column (someone did not put a numerical value)\n",
    "# Error because of wrong input in WORK column (someone did not put an integer as value)\n",
    "def check_convertible_to_float(x):\n",
    "    try:\n",
    "        float(x)  # Try to convert to float\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Apply the function to the WORK column to find non-convertible values\n",
    "non_convertible_rows = df[~df['WORK'].replace('%', '', regex=True).apply(check_convertible_to_float)]\n",
    "\n",
    "# Print the VPNCode of rows with non-convertible WORK values\n",
    "print(non_convertible_rows['VPNCode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    VPNCode WORK\n",
      "10  VBA1706   15\n"
     ]
    }
   ],
   "source": [
    "# Locate the row with VPNCode 'VBA1706' and update the WORK column value to 15 (Reason: in between 10 and 20 as before it was 10/20)\n",
    "df.loc[df['VPNCode'] == 'VBA1706', 'WORK'] = 15\n",
    "\n",
    "# Check the update by displaying the row to ensure the change has been made\n",
    "print(df[df['VPNCode'] == 'VBA1706'][['VPNCode', 'WORK']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with non-convertible WORK values after correction: []\n"
     ]
    }
   ],
   "source": [
    "# To identify and print non-convertible values again after manual correction\n",
    "non_convertible_after_correction = df[df['WORK'].isnull()]\n",
    "print(\"Rows with non-convertible WORK values after correction:\", non_convertible_after_correction['VPNCode'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      25.0\n",
      "1      15.0\n",
      "2      20.0\n",
      "3      30.0\n",
      "4      60.0\n",
      "5      20.0\n",
      "6      50.0\n",
      "7      50.0\n",
      "8      60.0\n",
      "9     100.0\n",
      "10     15.0\n",
      "11     10.0\n",
      "12    100.0\n",
      "Name: WORK, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert decimal representations to whole numbers for percentages\n",
    "df['WORK'] = df['WORK'].apply(lambda x: x*100 if x <= 1 else x)\n",
    "\n",
    "# Verify the changes\n",
    "print(df['WORK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants passed all tests\n"
     ]
    }
   ],
   "source": [
    "# Check if ERK and TEST columns have \"Ja\" for all rows (not sure if they could continue the survey but check for safety)\n",
    "# If all pass the two columns are dropped otherwise the VPNCodes are stated\n",
    "if (df['ERK'] == \"Ja\").all() and (df['TEST'] == \"Ja\").all():\n",
    "    print(\"Participants passed all tests\")\n",
    "    df.drop(columns=['ERK', 'TEST'], inplace=True)\n",
    "else:\n",
    "    failed_tests = df[(df['ERK'] != \"Ja\") | (df['TEST'] != \"Ja\")]['VPNCode']\n",
    "    print(f\"Not all participants passed the tests. Affected VPNCode rows: {failed_tests.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All WORK column numbers are > 0.\n"
     ]
    }
   ],
   "source": [
    "# Check if all numbers in the WORK column are > 0\n",
    "if (df['WORK'] <= 0).any():\n",
    "    affected_vpn = df[df['WORK'] <= 0]['VPNCode']\n",
    "    print(f\"WORK column contains values <= 0. Affected VPNCode rows: {affected_vpn.tolist()}\")\n",
    "else:\n",
    "    print(\"All WORK column numbers are > 0.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually drop the affected rows, if necessary\n",
    "# df = df[df['VPNCode'] != \"state all the VPNCodes\"]\n",
    "# df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants passed all AC tests\n"
     ]
    }
   ],
   "source": [
    "# Check if JC2[AC] column has 4 as an answer for all rows\n",
    "# If this is the case the column is dropped otherwise the VPNCodes are stated\n",
    "if (df['JC2[AC]'] == 4).all():\n",
    "    print(\"Participants passed all AC tests\")\n",
    "    df.drop(columns=['JC2[AC]'], inplace=True)\n",
    "else:\n",
    "    failed_ac_test = df[df['JC2[AC]'] != 4]['VPNCode']\n",
    "    print(f\"Not all participants passed the AC test. Affected VPNCode rows: {failed_ac_test.tolist()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually drop the affected rows, if necessary\n",
    "# df = df[df['VPNCode'] != \"state all the VPNCodes\"]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# After that, run again the cell above to drop the column 'JC2[AC]' as it is no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying rows with missing values and the specific columns affected (Problem: For JC1 it is possible to select \"Keine Antwort\". This is not possible for JC2)\n",
    "# If no VPNCodes are listed, everything is fine otherwise data is missing\n",
    "missing_info = df[df.isnull().any(axis=1)]\n",
    "for index, row in missing_info.iterrows():\n",
    "    missing_columns = row[row.isnull()].index.tolist()\n",
    "    print(f\"VPNCode: {row['VPNCode']}, Missing in columns: {missing_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually drop the affected rows, if necessary (or handle the missing data in another way)\n",
    "# df = df[df['VPNCode'] != \"state all the VPNCodes\"]\n",
    "# df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VPNCode  AGE  WORK  AILiteracy[Use1]  AILiteracy[Use2]  AILiteracy[Use3]  \\\n",
      "0  ABO2606   22  25.0                 3                 4                 3   \n",
      "1  APE2704   20  15.0                 5                 5                 5   \n",
      "2  SSG0102   20  20.0                 5                 4                 4   \n",
      "3  ECH2807   21  30.0                 4                 4                 4   \n",
      "4  AST1210   25  60.0                 5                 4                 4   \n",
      "\n",
      "   AILiteracy[Use4]  AILiteracy[Use5]  AILiteracy[Use6]  AILiteracy[Kno1]  \\\n",
      "0                 3                 3                 3                 4   \n",
      "1                 5                 5                 5                 5   \n",
      "2                 4                 4                 2                 5   \n",
      "3                 4                 4                 4                 5   \n",
      "4                 4                 4                 4                 4   \n",
      "\n",
      "   ...  groupTime534  groupTime533  groupTime535  groupTime536  total_time  \\\n",
      "0  ...     11.980833      1.290833      0.066833     11.509667        35.0   \n",
      "1  ...      6.372500      1.443167      0.180167     11.385000        23.0   \n",
      "2  ...     10.433000      1.658333     14.911000      2.625667        34.0   \n",
      "3  ...     21.664167      0.892167     19.574333      1.821167        46.0   \n",
      "4  ...     12.412667      1.634500      6.445500      2.959667        28.0   \n",
      "\n",
      "   Gender_Männlich  Gender_Weiblich  Edu_Abgeschlossene_Berufsausbildung  \\\n",
      "0                1                0                                    0   \n",
      "1                1                0                                    0   \n",
      "2                1                0                                    0   \n",
      "3                1                0                                    0   \n",
      "4                1                0                                    1   \n",
      "\n",
      "   Edu_Abitur_oder_Fachabitur  Edu_Bachelor  \n",
      "0                           0             1  \n",
      "1                           1             0  \n",
      "2                           1             0  \n",
      "3                           1             0  \n",
      "4                           0             0  \n",
      "\n",
      "[5 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF in a new CSV-File \n",
    "# df.to_csv('data_prep_cleaned.csv', index=False, encoding='utf-8-sig', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# df = pd.read_csv('ddata_prep_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Literacy Constructs\n",
    "df['AILiteracy[Use]'] = df[['AILiteracy[Use1]', 'AILiteracy[Use2]', 'AILiteracy[Use3]', 'AILiteracy[Use4]', 'AILiteracy[Use5]', 'AILiteracy[Use6]']].mean(axis=1)\n",
    "df['AILiteracy[Kno]'] = df[['AILiteracy[Kno1]', 'AILiteracy[Kno2]', 'AILiteracy[Kno3]', 'AILiteracy[Kno4]', 'AILiteracy[Kno5]', 'AILiteracy[Kno6]']].mean(axis=1)\n",
    "df['AILiteracy[Det]'] = df[['AILiteracy[Det1]', 'AILiteracy[Det2]', 'AILiteracy[Det3]']].mean(axis=1)\n",
    "df['AILiteracy[Eth]'] = df[['AILiteracy[Eth1]', 'AILiteracy[Eth3]']].mean(axis=1)\n",
    "\n",
    "# Maybe create only one AILiteracy construct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Attitudes towards AI Constructs\n",
    "df['PGAT'] = df[['PGAT[PGAT1]', 'PGAT[PGAT2]', 'PGAT[PGAT3]']].mean(axis=1)\n",
    "df['NGAT'] = df[['NGAT[NGAT1]', 'NGAT[NGAT2]', 'NGAT[NGAT3]']].mean(axis=1)\n",
    "\n",
    "# Maybe create only one Attitudes towards AI construct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Method Bias Construct\n",
    "df['CMV'] = df[['CMV[SQ001]', 'CMV[SQ002]', 'CMV[SQ003]']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Five Personality Traits (NEO) Constructs\n",
    "df['NEO[E]'] = df[['NEO[E1R]', 'NEO[E2]', 'NEO[E3R]', 'NEO[E4]']].mean(axis=1)\n",
    "df['NEO[A]'] = df[['NEO[V1R]', 'NEO[V2]', 'NEO[V3R]', 'NEO[V4R]']].mean(axis=1)\n",
    "df['NEO[C]'] = df[['NEO[G1]', 'NEO[G2R]', 'NEO[G3]', 'NEO[G4]']].mean(axis=1)\n",
    "df['NEO[N]'] = df[['NEO[N1]', 'NEO[N2R]', 'NEO[N3]', 'NEO[N4]']].mean(axis=1)\n",
    "df['NEO[O]'] = df[['NEO[O1]', 'NEO[O2]', 'NEO[O3]', 'NEO[O4]', 'NEO[O5R]']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job Crafting Constructs -> Changes necessary in comparison to second round\n",
    "df['JC1[IStR]'] = df[['JC1[IStR1]', 'JC1[IStR2]', 'JC1[IStR3]', 'JC1[IStR4]', 'JC1[IStR5]']].mean(axis=1)\n",
    "df['JC1[HRJD]'] = df[['JC1[HRJD1]', 'JC1[HRJD2]', 'JC1[HRJD3]']].mean(axis=1)\n",
    "df['JC1[ICJD]'] = df[['JC1[ICJD1]', 'JC1[ICJD2]']].mean(axis=1) #completely new in comparison to second round with randomization\n",
    "\n",
    "df['JC2[IStR]'] = df[['JC2[2IStR1]', 'JC2[2IStR2]', 'JC2[2IStR3]', 'JC2[2IStR4]', 'JC2[2IStR5]']].mean(axis=1)\n",
    "df['JC2[HRJD]'] = df[['JC2[2HRJD1]', 'JC2[2HRJD2]', 'JC2[2HRJD5]', 'JC2[2HRJD6]']].mean(axis=1) #added JC2[2HRJD6] in comparison to second round with randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original columns to clean up the DataFrame and reduce complexity\n",
    "columns_to_drop = [\n",
    "    'AILiteracy[Use1]', 'AILiteracy[Use2]', 'AILiteracy[Use3]', 'AILiteracy[Use4]', 'AILiteracy[Use5]', 'AILiteracy[Use6]',\n",
    "    'AILiteracy[Kno1]', 'AILiteracy[Kno2]', 'AILiteracy[Kno3]', 'AILiteracy[Kno4]', 'AILiteracy[Kno5]', 'AILiteracy[Kno6]',\n",
    "    'AILiteracy[Det1]', 'AILiteracy[Det2]', 'AILiteracy[Det3]', \n",
    "    'AILiteracy[Eth1]', 'AILiteracy[Eth3]',\n",
    "    'PGAT[PGAT1]', 'PGAT[PGAT2]', 'PGAT[PGAT3]',\n",
    "    'NGAT[NGAT1]', 'NGAT[NGAT2]', 'NGAT[NGAT3]',\n",
    "    'CMV[SQ001]', 'CMV[SQ002]', 'CMV[SQ003]',\n",
    "    'NEO[E1R]', 'NEO[E2]', 'NEO[E3R]', 'NEO[E4]',\n",
    "    'NEO[V1R]', 'NEO[V2]', 'NEO[V3R]', 'NEO[V4R]',\n",
    "    'NEO[G1]', 'NEO[G2R]', 'NEO[G3]', 'NEO[G4]',\n",
    "    'NEO[N1]', 'NEO[N2R]', 'NEO[N3]', 'NEO[N4]',\n",
    "    'NEO[O1]', 'NEO[O2]', 'NEO[O3]', 'NEO[O4]', 'NEO[O5R]',\n",
    "    'JC1[IStR1]', 'JC1[IStR2]', 'JC1[IStR3]', 'JC1[IStR4]', 'JC1[IStR5]',\n",
    "    'JC1[HRJD1]', 'JC1[HRJD2]', 'JC1[HRJD3]',\n",
    "    'JC1[ICJD1]', 'JC1[ICJD2]', #added both\n",
    "    'JC2[2IStR1]', 'JC2[2IStR2]', 'JC2[2IStR3]', 'JC2[2IStR4]', 'JC2[2IStR5]',\n",
    "    'JC2[2HRJD1]', 'JC2[2HRJD2]', 'JC2[2HRJD5]', 'JC2[2HRJD6]' #added JC2[2HRJD6] \n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming rest of the columns\n",
    "df.rename(columns={\n",
    "    'SDT1[SDT1]': 'SDT1[AUT]',\n",
    "    'SDT1[SDT2]': 'SDT1[COM]',\n",
    "    'SDT2[2SDT1]': 'SDT2[AUT]',\n",
    "    'SDT2[2SDT2]': 'SDT2[COM]'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VPNCode', 'AGE', 'WORK', 'SE1', 'SDT1[AUT]', 'SDT1[COM]', 'PROD1[SQ001]', 'TASKDIF1[SQ001]', 'SE2', 'SDT2[AUT]', 'SDT2[COM]', 'PROD2[SQ001]', 'TASKDIF2[SQ001]', 'MANI2', 'interviewtime', 'groupTime531', 'groupTime532', 'groupTime534', 'groupTime533', 'groupTime535', 'groupTime536', 'total_time', 'Gender_Männlich', 'Gender_Weiblich', 'Edu_Abgeschlossene_Berufsausbildung', 'Edu_Abitur_oder_Fachabitur', 'Edu_Bachelor', 'AILiteracy[Use]', 'AILiteracy[Kno]', 'AILiteracy[Det]', 'AILiteracy[Eth]', 'PGAT', 'NGAT', 'CMV', 'NEO[E]', 'NEO[A]', 'NEO[C]', 'NEO[N]', 'NEO[O]', 'JC1[IStR]', 'JC1[HRJD]', 'JC1[ICJD]', 'JC2[IStR]', 'JC2[HRJD]']\n"
     ]
    }
   ],
   "source": [
    "# Show all the columns in the dataset as list -> Quick check\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the desired order of columns\n",
    "# If any are missing or named differently, adjust the list accordingly.\n",
    "new_column_order = [\n",
    "    'VPNCode', 'AGE', 'WORK', \n",
    "    'Gender_Männlich', 'Gender_Weiblich', 'Edu_Abitur_oder_Fachabitur', 'Edu_Bachelor',\n",
    "    'AILiteracy[Use]', 'AILiteracy[Kno]', 'AILiteracy[Det]', 'AILiteracy[Eth]',\n",
    "    'PGAT', 'NGAT', 'CMV', 'NEO[E]', 'NEO[A]', 'NEO[C]', 'NEO[N]', 'NEO[O]',\n",
    "    'JC1[IStR]', 'JC1[HRJD]', 'JC1[ICJD]', 'SE1', 'SDT1[AUT]', 'SDT1[COM]', 'PROD1[SQ001]', 'TASKDIF1[SQ001]',\n",
    "    'JC2[IStR]', 'JC2[HRJD]', 'SE2', 'SDT2[AUT]', 'SDT2[COM]', 'PROD2[SQ001]', 'TASKDIF2[SQ001]', 'MANI2',\n",
    "    'total_time', 'interviewtime', 'groupTime531', 'groupTime532', 'groupTime534', 'groupTime533', 'groupTime535', 'groupTime536'\n",
    "]\n",
    "\n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming time columns (taken from the German translation)\n",
    "df.rename(columns={\n",
    "    'interviewtime': 'syst_total_time',\n",
    "    'groupTime531': 'time_demogr',\n",
    "    'groupTime532': 'time_pers',\n",
    "    'groupTime534': 'time_task1',\n",
    "    'groupTime533': 'time_survey1',\n",
    "    'groupTime535': 'time_task2',\n",
    "    'groupTime536': 'time_survey1'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VPNCode  AGE  WORK  Gender_Männlich  Gender_Weiblich  \\\n",
      "0  ABO2606   22  25.0                1                0   \n",
      "1  APE2704   20  15.0                1                0   \n",
      "2  SSG0102   20  20.0                1                0   \n",
      "3  ECH2807   21  30.0                1                0   \n",
      "4  AST1210   25  60.0                1                0   \n",
      "\n",
      "   Edu_Abitur_oder_Fachabitur  Edu_Bachelor  AILiteracy[Use]  AILiteracy[Kno]  \\\n",
      "0                           0             1         3.166667         3.333333   \n",
      "1                           1             0         5.000000         4.833333   \n",
      "2                           1             0         3.833333         4.333333   \n",
      "3                           1             0         4.000000         4.500000   \n",
      "4                           0             0         4.166667         3.833333   \n",
      "\n",
      "   AILiteracy[Det]  AILiteracy[Eth]      PGAT      NGAT       CMV  NEO[E]  \\\n",
      "0         4.000000              2.5  4.000000  2.666667  4.666667    2.75   \n",
      "1         3.333333              3.5  4.000000  3.333333  2.000000    2.25   \n",
      "2         3.333333              2.0  3.333333  2.333333  3.666667    3.75   \n",
      "3         4.666667              3.0  3.333333  3.333333  4.000000    3.00   \n",
      "4         4.000000              3.0  3.000000  3.333333  4.333333    3.00   \n",
      "\n",
      "   NEO[A]  NEO[C]  NEO[N]  NEO[O]  JC1[IStR]  JC1[HRJD]  JC1[ICJD]  SE1  \\\n",
      "0    3.00    3.75    2.50     3.6        2.8   2.333333        3.0  100   \n",
      "1    3.25    4.00    2.25     3.6        3.0   2.333333        3.0  100   \n",
      "2    3.50    3.50    2.25     4.0        3.8   3.666667        3.5   70   \n",
      "3    3.50    3.25    2.50     4.0        3.4   3.333333        2.5  100   \n",
      "4    4.00    3.75    3.00     4.2        4.4   3.666667        4.5  100   \n",
      "\n",
      "   SDT1[AUT]  SDT1[COM]  PROD1[SQ001]  TASKDIF1[SQ001]  JC2[IStR]  JC2[HRJD]  \\\n",
      "0          2          3             4                2        2.8       4.00   \n",
      "1          3          4             3                4        4.6       4.00   \n",
      "2          5          2             2                3        5.0       2.75   \n",
      "3          5          4             4                3        3.8       3.75   \n",
      "4          5          4             4                2        3.2       5.00   \n",
      "\n",
      "   SE2  SDT2[AUT]  SDT2[COM]  PROD2[SQ001]  TASKDIF2[SQ001]  \\\n",
      "0   20          3          5             3                4   \n",
      "1    5          3          5             4                4   \n",
      "2   80          4          4             4                3   \n",
      "3   70          3          5             4                3   \n",
      "4   15          4          5             3                4   \n",
      "\n",
      "                                               MANI2  total_time  \\\n",
      "0  In der zweiten Aufgabe musste ich ein Konzept ...        35.0   \n",
      "1  Ich musste einen Plan für eine einwöchige Vera...        23.0   \n",
      "2  Ich musste einen Abend organisieren für eine e...        34.0   \n",
      "3  Ich musste für ein Unternehmen, über das ich k...        46.0   \n",
      "4  In der zweiten Aufgabe ging es um eine einwöch...        28.0   \n",
      "\n",
      "   syst_total_time  time_demogr  time_pers  time_task1  time_survey1  \\\n",
      "0        35.038667     9.134167   1.056333   11.980833      1.290833   \n",
      "1        23.169333     2.530833   1.257667    6.372500      1.443167   \n",
      "2        34.525167     3.595667   1.301500   10.433000      1.658333   \n",
      "3        46.279833     1.717167   0.610833   21.664167      0.892167   \n",
      "4        28.102000     3.470833   1.178833   12.412667      1.634500   \n",
      "\n",
      "   time_task2  time_survey1  \n",
      "0    0.066833     11.509667  \n",
      "1    0.180167     11.385000  \n",
      "2   14.911000      2.625667  \n",
      "3   19.574333      1.821167  \n",
      "4    6.445500      2.959667  \n"
     ]
    }
   ],
   "source": [
    "# Display the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF in a new CSV-File \n",
    "df.to_csv('data_prep_constructs.csv', index=False, encoding='utf-8-sig', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
